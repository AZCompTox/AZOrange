diff -crBN AZOrange/orangeDependencies/src/opencv-2.0.0/include/opencv/ml.h AZOrangeExported/orangeDependencies/src/opencv-2.0.0/include/opencv/ml.h
*** AZOrange/orangeDependencies/src/opencv-2.0.0/include/opencv/ml.h	2009-10-01 01:20:57.000000000 +0100
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/include/opencv/ml.h	2011-01-20 14:15:22.593769791 +0000
***************
*** 1084,1105 ****
  public:
      CvRTrees();
      virtual ~CvRTrees();
      virtual bool train( const CvMat* _train_data, int _tflag,
                          const CvMat* _responses, const CvMat* _var_idx=0,
                          const CvMat* _sample_idx=0, const CvMat* _var_type=0,
                          const CvMat* _missing_mask=0,
!                         CvRTParams params=CvRTParams() );
!     
      virtual bool train( CvMLData* data, CvRTParams params=CvRTParams() );
      virtual float predict( const CvMat* sample, const CvMat* missing = 0 ) const;
      virtual float predict_prob( const CvMat* sample, const CvMat* missing = 0 ) const;
  
  #ifndef SWIG
      virtual bool train( const cv::Mat& _train_data, int _tflag,
                         const cv::Mat& _responses, const cv::Mat& _var_idx=cv::Mat(),
                         const cv::Mat& _sample_idx=cv::Mat(), const cv::Mat& _var_type=cv::Mat(),
                         const cv::Mat& _missing_mask=cv::Mat(),
!                        CvRTParams params=CvRTParams() );
      virtual float predict( const cv::Mat& sample, const cv::Mat& missing = cv::Mat() ) const;
      virtual float predict_prob( const cv::Mat& sample, const cv::Mat& missing = cv::Mat() ) const;
  #endif
--- 1083,1107 ----
  public:
      CvRTrees();
      virtual ~CvRTrees();
+     //scPA  Added the parameters cls_count and priorsStr
      virtual bool train( const CvMat* _train_data, int _tflag,
                          const CvMat* _responses, const CvMat* _var_idx=0,
                          const CvMat* _sample_idx=0, const CvMat* _var_type=0,
                          const CvMat* _missing_mask=0,
!                         CvRTParams params=CvRTParams(),const int cls_count = 0, char* priorsStr = NULL);
!     //ecPA
      virtual bool train( CvMLData* data, CvRTParams params=CvRTParams() );
      virtual float predict( const CvMat* sample, const CvMat* missing = 0 ) const;
      virtual float predict_prob( const CvMat* sample, const CvMat* missing = 0 ) const;
  
  #ifndef SWIG
+     //scPA  Added the parameters cls_count and priorsStr
      virtual bool train( const cv::Mat& _train_data, int _tflag,
                         const cv::Mat& _responses, const cv::Mat& _var_idx=cv::Mat(),
                         const cv::Mat& _sample_idx=cv::Mat(), const cv::Mat& _var_type=cv::Mat(),
                         const cv::Mat& _missing_mask=cv::Mat(),
!                        CvRTParams params=CvRTParams(), const int cls_count = 0, char*  priorsStr=NULL );
!     //ecPA
      virtual float predict( const cv::Mat& sample, const cv::Mat& missing = cv::Mat() ) const;
      virtual float predict_prob( const cv::Mat& sample, const cv::Mat& missing = cv::Mat() ) const;
  #endif
***************
*** 1407,1413 ****
      virtual int train( const CvMat* _inputs, const CvMat* _outputs,
                         const CvMat* _sample_weights, const CvMat* _sample_idx=0,
                         CvANN_MLP_TrainParams _params = CvANN_MLP_TrainParams(),
!                        int flags=0 );
      virtual float predict( const CvMat* _inputs, CvMat* _outputs ) const;
      
  #ifndef SWIG
--- 1409,1415 ----
      virtual int train( const CvMat* _inputs, const CvMat* _outputs,
                         const CvMat* _sample_weights, const CvMat* _sample_idx=0,
                         CvANN_MLP_TrainParams _params = CvANN_MLP_TrainParams(),
!                        int flags=0, int seed=0, int nIterStep=0, const CvMat* _inputs_val=0, const CvMat* _outputs_val=0);
      virtual float predict( const CvMat* _inputs, CvMat* _outputs ) const;
      
  #ifndef SWIG
***************
*** 1422,1428 ****
      virtual int train( const cv::Mat& _inputs, const cv::Mat& _outputs,
                        const cv::Mat& _sample_weights, const cv::Mat& _sample_idx=cv::Mat(),
                        CvANN_MLP_TrainParams _params = CvANN_MLP_TrainParams(),
!                       int flags=0 );    
      
      virtual float predict( const cv::Mat& _inputs, cv::Mat& _outputs ) const;
  #endif
--- 1424,1430 ----
      virtual int train( const cv::Mat& _inputs, const cv::Mat& _outputs,
                        const cv::Mat& _sample_weights, const cv::Mat& _sample_idx=cv::Mat(),
                        CvANN_MLP_TrainParams _params = CvANN_MLP_TrainParams(),
!                       int flags=0, int seed=0, int nIterStep=0, const cv::Mat& _inputs_val=0, const cv::Mat& _outputs_val=0);    
      
      virtual float predict( const cv::Mat& _inputs, cv::Mat& _outputs ) const;
  #endif
***************
*** 1456,1468 ****
      virtual int train_backprop( CvVectors _ivecs, CvVectors _ovecs, const double* _sw );
  
      // RPROP algorithm
!     virtual int train_rprop( CvVectors _ivecs, CvVectors _ovecs, const double* _sw );
  
      virtual void calc_activ_func( CvMat* xf, const double* bias ) const;
      virtual void calc_activ_func_deriv( CvMat* xf, CvMat* deriv, const double* bias ) const;
      virtual void set_activ_func( int _activ_func=SIGMOID_SYM,
                                   double _f_param1=0, double _f_param2=0 );
!     virtual void init_weights();
      virtual void scale_input( const CvMat* _src, CvMat* _dst ) const;
      virtual void scale_output( const CvMat* _src, CvMat* _dst ) const;
      virtual void calc_input_scale( const CvVectors* vecs, int flags );
--- 1458,1470 ----
      virtual int train_backprop( CvVectors _ivecs, CvVectors _ovecs, const double* _sw );
  
      // RPROP algorithm
!     virtual int train_rprop( CvVectors _ivecs, CvVectors _ovecs, const double* _sw, int nIterStep=0, const CvMat* _inputs_val=0, const CvMat* _outputs_val=0);
  
      virtual void calc_activ_func( CvMat* xf, const double* bias ) const;
      virtual void calc_activ_func_deriv( CvMat* xf, CvMat* deriv, const double* bias ) const;
      virtual void set_activ_func( int _activ_func=SIGMOID_SYM,
                                   double _f_param1=0, double _f_param2=0 );
!     virtual void init_weights(int seed);
      virtual void scale_input( const CvMat* _src, CvMat* _dst ) const;
      virtual void scale_output( const CvMat* _src, CvMat* _dst ) const;
      virtual void calc_input_scale( const CvVectors* vecs, int flags );
diff -crBN AZOrange/orangeDependencies/src/opencv-2.0.0/interfaces/swig/python/_ml.cpp AZOrangeExported/orangeDependencies/src/opencv-2.0.0/interfaces/swig/python/_ml.cpp
*** AZOrange/orangeDependencies/src/opencv-2.0.0/interfaces/swig/python/_ml.cpp	2009-10-01 01:20:56.000000000 +0100
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/interfaces/swig/python/_ml.cpp	2011-01-21 12:20:28.177727597 +0000
***************
*** 32824,32829 ****
--- 32824,32833 ----
    CvMat *arg7 = (CvMat *) 0 ;
    CvMat *arg8 = (CvMat *) 0 ;
    CvRTParams arg9 ;
+ //scPA
+   int arg10;
+   char *arg11 = (char *) 0 ;
+ //ecPA
    void *argp1 = 0 ;
    int res1 = 0 ;
    bool freearg2 = false ;
***************
*** 32836,32841 ****
--- 32840,32853 ----
    bool freearg8 = false ;
    void *argp9 ;
    int res9 = 0 ;
+ //scPA
+   int val10;
+   int res10 = 0 ;
+   int val11;
+   int res11 = 0 ;
+   char *buf11 = 0 ;
+   int alloc11 = 0 ;
+ //ecPA
    PyObject * obj0 = 0 ;
    PyObject * obj1 = 0 ;
    PyObject * obj2 = 0 ;
***************
*** 32845,32853 ****
    PyObject * obj6 = 0 ;
    PyObject * obj7 = 0 ;
    PyObject * obj8 = 0 ;
    bool result;
!   
!   if (!PyArg_ParseTuple(args,(char *)"OOOOOOOOO:CvRTrees_train",&obj0,&obj1,&obj2,&obj3,&obj4,&obj5,&obj6,&obj7,&obj8)) SWIG_fail;
    res1 = SWIG_ConvertPtr(obj0, &argp1,SWIGTYPE_p_CvRTrees, 0 |  0 );
    if (!SWIG_IsOK(res1)) {
      SWIG_exception_fail(SWIG_ArgError(res1), "in method '" "CvRTrees_train" "', argument " "1"" of type '" "CvRTrees *""'"); 
--- 32857,32870 ----
    PyObject * obj6 = 0 ;
    PyObject * obj7 = 0 ;
    PyObject * obj8 = 0 ;
+ //scPA
+   PyObject * obj9 = 0 ;
+   PyObject * obj10 = 0 ;
+ //ecPA
+ 
    bool result;
! //scPA Added 2 parameters OO....obj9,&obj10  
!   if (!PyArg_ParseTuple(args,(char *)"OOOOOOOOOOO:CvRTrees_train",&obj0,&obj1,&obj2,&obj3,&obj4,&obj5,&obj6,&obj7,&obj8,&obj9,&obj10)) SWIG_fail;
    res1 = SWIG_ConvertPtr(obj0, &argp1,SWIGTYPE_p_CvRTrees, 0 |  0 );
    if (!SWIG_IsOK(res1)) {
      SWIG_exception_fail(SWIG_ArgError(res1), "in method '" "CvRTrees_train" "', argument " "1"" of type '" "CvRTrees *""'"); 
***************
*** 32889,32897 ****
        if (SWIG_IsNewObj(res9)) delete temp;
      }
    }
    {
      try {
!       result = (bool)(arg1)->train((CvMat const *)arg2,arg3,(CvMat const *)arg4,(CvMat const *)arg5,(CvMat const *)arg6,(CvMat const *)arg7,(CvMat const *)arg8,arg9); 
      } 
      catch (...) 
      {
--- 32906,32930 ----
        if (SWIG_IsNewObj(res9)) delete temp;
      }
    }
+   //scPA
+   res10 = SWIG_AsVal_int(obj9, &val10);
+   if (!SWIG_IsOK(res10)) {
+     SWIG_exception_fail(SWIG_ArgError(res10), "in method '" "CvRTrees_train" "', argument " "10"" of type '" "int""'");
+   }
+   arg10 = static_cast< int >(val10);
+ 
+   res11 = SWIG_AsCharPtrAndSize(obj10, &buf11, NULL, &alloc11);
+   if (!SWIG_IsOK(res11)) {
+     SWIG_exception_fail(SWIG_ArgError(res11), "in method '" "CvRTrees_train" "', argument " "11"" of type '" "char const *""'");
+   }
+   arg11 = reinterpret_cast< char * >(buf11);
+   //ecPA
    {
      try {
!       //scPA - Added 2 parameters
!       result = (bool)(arg1)->train((CvMat const *)arg2,arg3,(CvMat const *)arg4,(CvMat const *)arg5,(CvMat const *)arg6,(CvMat const *)arg7,(CvMat const *)arg8,arg9,arg10,arg11);
!       //ecPA
!     //result = (bool)(arg1)->train((CvMat const *)arg2,arg3,(CvMat const *)arg4,(CvMat const *)arg5,(CvMat const *)arg6,(CvMat const *)arg7,(CvMat const *)arg8,arg9); 
      } 
      catch (...) 
      {
***************
*** 33629,33640 ****
  
  SWIGINTERN PyObject *_wrap_CvRTrees_train(PyObject *self, PyObject *args) {
    int argc;
!   PyObject *argv[10];
    int ii;
    
    if (!PyTuple_Check(args)) SWIG_fail;
    argc = (int)PyObject_Length(args);
!   for (ii = 0; (ii < argc) && (ii < 9); ii++) {
      argv[ii] = PyTuple_GET_ITEM(args,ii);
    }
    if (argc == 2) {
--- 33662,33677 ----
  
  SWIGINTERN PyObject *_wrap_CvRTrees_train(PyObject *self, PyObject *args) {
    int argc;
!   //scPA   Added 2 oarameters: 10 -> 12
!   PyObject *argv[12];
!   //ecPA
! 
    int ii;
    
    if (!PyTuple_Check(args)) SWIG_fail;
    argc = (int)PyObject_Length(args);
!   //scPA  Added 2 for the iii lomit   //ecPA
!   for (ii = 0; (ii < argc) && (ii < 11); ii++) {
      argv[ii] = PyTuple_GET_ITEM(args,ii);
    }
    if (argc == 2) {
***************
*** 33844,33850 ****
        }
      }
    }
!   if (argc == 9) {
      int _v;
      void *vptr = 0;
      int res = SWIG_ConvertPtr(argv[0], &vptr, SWIGTYPE_p_CvRTrees, 0);
--- 33881,33888 ----
        }
      }
    }
!   //scPA argc == 9 -> added 2 parameters
!   if (argc == 11) {
      int _v;
      void *vptr = 0;
      int res = SWIG_ConvertPtr(argv[0], &vptr, SWIGTYPE_p_CvRTrees, 0);
***************
*** 33882,33888 ****
                      int res = SWIG_ConvertPtr(argv[8], 0, SWIGTYPE_p_CvRTParams, 0);
                      _v = SWIG_CheckState(res);
                      if (_v) {
!                       return _wrap_CvRTrees_train__SWIG_0(self, args);
                      }
                    }
                  }
--- 33920,33935 ----
                      int res = SWIG_ConvertPtr(argv[8], 0, SWIGTYPE_p_CvRTParams, 0);
                      _v = SWIG_CheckState(res);
                      if (_v) {
!                       int res = SWIG_AsVal_int(argv[9], NULL);
!                       _v = SWIG_CheckState(res);
!                       if (_v) {                        char *cptr = 0;
!                         int alloc = 0;
!                         int res = SWIG_AsCharPtrAndSize(argv[10], &cptr, NULL, &alloc);
!                         _v = SWIG_CheckState(res);
!                         if (_v) {
!                           return _wrap_CvRTrees_train__SWIG_0(self, args);
!                         }
!                       }
                      }
                    }
                  }
***************
*** 33893,33913 ****
        }
      }
    }
!   
  fail:
    SWIG_SetErrorMsg(PyExc_NotImplementedError,"Wrong number of arguments for overloaded function 'CvRTrees_train'.\n"
      "  Possible C/C++ prototypes are:\n"
!     "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvRTParams)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *)\n"
!     "    train(CvRTrees *,CvMat const *,int,CvMat const *)\n"
!     "    train(CvRTrees *,CvMLData *,CvRTParams)\n"
!     "    train(CvRTrees *,CvMLData *)\n");
    return NULL;
  }
  
  
  SWIGINTERN PyObject *_wrap_CvRTrees_predict__SWIG_0(PyObject *SWIGUNUSEDPARM(self), PyObject *args) {
    PyObject *resultobj = 0;
--- 33940,33960 ----
        }
      }
    }
! 
  fail:
    SWIG_SetErrorMsg(PyExc_NotImplementedError,"Wrong number of arguments for overloaded function 'CvRTrees_train'.\n"
      "  Possible C/C++ prototypes are:\n"
!     "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvRTParams, const int cls_count, char * priorsStr)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvRTrees *,CvMat const *,int,CvMat const *,CvMat const *)\n"
!     "    train(CvRTrees *,CvMat const *,int,CvMat const *)\n");
    return NULL;
  }
  
+ //ecPA
+ 
  
  SWIGINTERN PyObject *_wrap_CvRTrees_predict__SWIG_0(PyObject *SWIGUNUSEDPARM(self), PyObject *args) {
    PyObject *resultobj = 0;
***************
*** 45742,45757 ****
--- 45789,45818 ----
    CvMat *arg5 = (CvMat *) 0 ;
    CvANN_MLP_TrainParams arg6 ;
    int arg7 ;
+   //scPA
+   int arg8 ;
+   int arg9 ;
+   CvMat *arg10 = (CvMat *) 0 ;
+   CvMat *arg11 = (CvMat *) 0 ;
+   //ecPA
    void *argp1 = 0 ;
    int res1 = 0 ;
    bool freearg2 = false ;
    bool freearg3 = false ;
    bool freearg4 = false ;
    bool freearg5 = false ;
+   bool freearg10 = false ;
+   bool freearg11 = false ;
    void *argp6 ;
    int res6 = 0 ;
    int val7 ;
    int ecode7 = 0 ;
+   //scPA
+   int val8 ;
+   int ecode8 = 0 ;
+   int val9 ;
+   int ecode9 = 0 ;
+   //ecPA
    PyObject * obj0 = 0 ;
    PyObject * obj1 = 0 ;
    PyObject * obj2 = 0 ;
***************
*** 45759,45767 ****
    PyObject * obj4 = 0 ;
    PyObject * obj5 = 0 ;
    PyObject * obj6 = 0 ;
    int result;
!   
!   if (!PyArg_ParseTuple(args,(char *)"OOOOOOO:CvANN_MLP_train",&obj0,&obj1,&obj2,&obj3,&obj4,&obj5,&obj6)) SWIG_fail;
    res1 = SWIG_ConvertPtr(obj0, &argp1,SWIGTYPE_p_CvANN_MLP, 0 |  0 );
    if (!SWIG_IsOK(res1)) {
      SWIG_exception_fail(SWIG_ArgError(res1), "in method '" "CvANN_MLP_train" "', argument " "1"" of type '" "CvANN_MLP *""'"); 
--- 45820,45834 ----
    PyObject * obj4 = 0 ;
    PyObject * obj5 = 0 ;
    PyObject * obj6 = 0 ;
+   //scPA
+   PyObject * obj7 = 0 ;
+   PyObject * obj8 = 0 ;
+   PyObject * obj9 = 0 ;
+   PyObject * obj10 = 0 ;
+   //ecPA
    int result;
!   //scPA Added 4 parameters O00O....obj7,&obj8,obj9,&obj10
!   if (!PyArg_ParseTuple(args,(char *)"OOOOOOOOOOO:CvANN_MLP_train",&obj0,&obj1,&obj2,&obj3,&obj4,&obj5,&obj6,&obj7,&obj8,&obj9,&obj10)) SWIG_fail;
    res1 = SWIG_ConvertPtr(obj0, &argp1,SWIGTYPE_p_CvANN_MLP, 0 |  0 );
    if (!SWIG_IsOK(res1)) {
      SWIG_exception_fail(SWIG_ArgError(res1), "in method '" "CvANN_MLP_train" "', argument " "1"" of type '" "CvANN_MLP *""'"); 
***************
*** 45797,45805 ****
      SWIG_exception_fail(SWIG_ArgError(ecode7), "in method '" "CvANN_MLP_train" "', argument " "7"" of type '" "int""'");
    } 
    arg7 = static_cast< int >(val7);
    {
      try {
!       result = (int)(arg1)->train((CvMat const *)arg2,(CvMat const *)arg3,(CvMat const *)arg4,(CvMat const *)arg5,arg6,arg7); 
      } 
      catch (...) 
      {
--- 45864,45893 ----
      SWIG_exception_fail(SWIG_ArgError(ecode7), "in method '" "CvANN_MLP_train" "', argument " "7"" of type '" "int""'");
    } 
    arg7 = static_cast< int >(val7);
+   //scPA
+   ecode8 = SWIG_AsVal_int(obj7, &val8);
+   if (!SWIG_IsOK(ecode8)) {
+     SWIG_exception_fail(SWIG_ArgError(ecode8), "in method '" "CvANN_MLP_train" "', argument " "8"" of type '" "int""'");
+   }
+   arg8 = static_cast< int >(val8);
+ 
+   ecode9 = SWIG_AsVal_int(obj8, &val9);
+   if (!SWIG_IsOK(ecode9)) {
+     SWIG_exception_fail(SWIG_ArgError(ecode9), "in method '" "CvANN_MLP_train" "', argument " "9"" of type '" "int""'");
+   }
+   arg9 = static_cast< int >(val9);
+ 
+   {
+     arg10 = (CvMat*)PyObject_to_CvArr(obj9, &freearg10);
+   }
+   {
+     arg11 = (CvMat*)PyObject_to_CvArr(obj10, &freearg11);
+   }
+ 
+   //ecPA
    {
      try {
!       result = (int)(arg1)->train((CvMat const *)arg2,(CvMat const *)arg3,(CvMat const *)arg4,(CvMat const *)arg5,arg6,arg7,arg8,arg9,(CvMat const *)arg10,(CvMat const *)arg11); 
      } 
      catch (...) 
      {
***************
*** 45831,45836 ****
--- 45919,45938 ----
        cvFree(&(arg5));
      }
    }
+   //scPA
+   {
+     if(arg10!=NULL && freearg10){
+       cvReleaseData( arg10 );
+       cvFree(&(arg10));
+     }
+   }
+   {
+     if(arg11!=NULL && freearg11){
+       cvReleaseData( arg11 );
+       cvFree(&(arg11));
+     }
+   }
+   //ecPA
    return resultobj;
  fail:
    {
***************
*** 45857,45862 ****
--- 45959,45978 ----
        cvFree(&(arg5));
      }
    }
+   //scPA
+   {
+     if(arg10!=NULL && freearg10){
+       cvReleaseData( arg10 );
+       cvFree(&(arg10));
+     }
+   }
+   {
+     if(arg11!=NULL && freearg11){
+       cvReleaseData( arg11 );
+       cvFree(&(arg11));
+     }
+   }
+   //ecPA
    return NULL;
  }
  
***************
*** 46168,46179 ****
  
  SWIGINTERN PyObject *_wrap_CvANN_MLP_train(PyObject *self, PyObject *args) {
    int argc;
!   PyObject *argv[8];
    int ii;
-   
    if (!PyTuple_Check(args)) SWIG_fail;
    argc = (int)PyObject_Length(args);
!   for (ii = 0; (ii < argc) && (ii < 7); ii++) {
      argv[ii] = PyTuple_GET_ITEM(args,ii);
    }
    if (argc == 4) {
--- 46284,46297 ----
  
  SWIGINTERN PyObject *_wrap_CvANN_MLP_train(PyObject *self, PyObject *args) {
    int argc;
!   //scPA Added 4 parameters: 8 -> 12
!   PyObject *argv[12];
!   //ecPA
    int ii;
    if (!PyTuple_Check(args)) SWIG_fail;
    argc = (int)PyObject_Length(args);
!   //scPA  Added 4 for the ii limit   //ecPA
!   for (ii = 0; (ii < argc) && (ii < 11); ii++) {
      argv[ii] = PyTuple_GET_ITEM(args,ii);
    }
    if (argc == 4) {
***************
*** 46262,46268 ****
        }
      }
    }
!   if (argc == 7) {
      int _v;
      void *vptr = 0;
      int res = SWIG_ConvertPtr(argv[0], &vptr, SWIGTYPE_p_CvANN_MLP, 0);
--- 46380,46386 ----
        }
      }
    }
!   if (argc == 11) {
      int _v;
      void *vptr = 0;
      int res = SWIG_ConvertPtr(argv[0], &vptr, SWIGTYPE_p_CvANN_MLP, 0);
***************
*** 46287,46298 ****
                int res = SWIG_ConvertPtr(argv[5], 0, SWIGTYPE_p_CvANN_MLP_TrainParams, 0);
                _v = SWIG_CheckState(res);
                if (_v) {
!                 {
!                   int res = SWIG_AsVal_int(argv[6], NULL);
!                   _v = SWIG_CheckState(res);
!                 }
                  if (_v) {
!                   return _wrap_CvANN_MLP_train__SWIG_0(self, args);
                  }
                }
              }
--- 46405,46434 ----
                int res = SWIG_ConvertPtr(argv[5], 0, SWIGTYPE_p_CvANN_MLP_TrainParams, 0);
                _v = SWIG_CheckState(res);
                if (_v) {
!                 int res = SWIG_AsVal_int(argv[6], NULL);
!                 _v = SWIG_CheckState(res);
                  if (_v) {
!                   int res = SWIG_AsVal_int(argv[7], NULL);
!                   _v = SWIG_CheckState(res);
!                   if (_v) {
!                     int res = SWIG_AsVal_int(argv[8], NULL);
!                     _v = SWIG_CheckState(res);
!                     if (_v) {
!                       void *vptr = 0;
!                       int res = SWIG_ConvertPtr(argv[9], &vptr, SWIGTYPE_p_CvMat, 0);
!                       _v = SWIG_CheckState(res);
!                       if (_v) {
!                         {
!                           void *vptr = 0;
!                           int res = SWIG_ConvertPtr(argv[10], &vptr, SWIGTYPE_p_CvMat, 0);
!                           _v = SWIG_CheckState(res);
!                         }   
!                         if (_v) {
!                           return _wrap_CvANN_MLP_train__SWIG_0(self, args);
!                         }
!                       }
!                     }
!                   }
                  }
                }
              }
***************
*** 46305,46311 ****
  fail:
    SWIG_SetErrorMsg(PyExc_NotImplementedError,"Wrong number of arguments for overloaded function 'CvANN_MLP_train'.\n"
      "  Possible C/C++ prototypes are:\n"
!     "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvANN_MLP_TrainParams,int)\n"
      "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvANN_MLP_TrainParams)\n"
      "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *)\n");
--- 46441,46447 ----
  fail:
    SWIG_SetErrorMsg(PyExc_NotImplementedError,"Wrong number of arguments for overloaded function 'CvANN_MLP_train'.\n"
      "  Possible C/C++ prototypes are:\n"
!     "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvANN_MLP_TrainParams,int,int,int,CvMat const *,CvMat const *)\n"
      "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *,CvMat const *,CvANN_MLP_TrainParams)\n"
      "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *,CvMat const *)\n"
      "    train(CvANN_MLP *,CvMat const *,CvMat const *,CvMat const *)\n");
diff -crBN AZOrange/orangeDependencies/src/opencv-2.0.0/src/ml/ml_inner_functions.cpp AZOrangeExported/orangeDependencies/src/opencv-2.0.0/src/ml/ml_inner_functions.cpp
*** AZOrange/orangeDependencies/src/opencv-2.0.0/src/ml/ml_inner_functions.cpp	2009-10-01 01:20:59.000000000 +0100
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/src/ml/ml_inner_functions.cpp	2011-01-05 12:13:49.749727230 +0000
***************
*** 588,598 ****
  
      r_step = responses->step ? responses->step / CV_ELEM_SIZE(responses->type) : 1;
  
      if( r_type == CV_32FC1 && CV_IS_MAT_CONT(responses->type) && !sample_idx )
      {
!         out_responses = (CvMat*)responses;
          EXIT;
      }
  
      if( sample_idx )
      {
--- 588,602 ----
  
      r_step = responses->step ? responses->step / CV_ELEM_SIZE(responses->type) : 1;
  
+     //scPA   we cannot return the same pointer, we need to create a new object since the train function  how called
+     //       will delete the returned out_responses when train is done.
      if( r_type == CV_32FC1 && CV_IS_MAT_CONT(responses->type) && !sample_idx )
      {
!         //out_responses = (CvMat*)responses;
!         out_responses = cvCloneMat((CvMat*)responses);
          EXIT;
      }
+     //ecPA
  
      if( sample_idx )
      {
diff -crBN AZOrange/orangeDependencies/src/opencv-2.0.0/src/ml/mlrtrees.cpp AZOrangeExported/orangeDependencies/src/opencv-2.0.0/src/ml/mlrtrees.cpp
*** AZOrange/orangeDependencies/src/opencv-2.0.0/src/ml/mlrtrees.cpp	2009-10-01 01:20:59.000000000 +0100
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/src/ml/mlrtrees.cpp	2011-01-05 12:13:49.749727230 +0000
***************
*** 39,44 ****
--- 39,49 ----
  //M*/
  
  #include "_ml.h"
+ #include <string>
+ #include <stdio.h>
+ #include <vector>
+ #include <sstream>
+ using namespace std;
  
  CvForestTree::CvForestTree()
  {
***************
*** 255,263 ****
  bool CvRTrees::train( const CvMat* _train_data, int _tflag,
                          const CvMat* _responses, const CvMat* _var_idx,
                          const CvMat* _sample_idx, const CvMat* _var_type,
!                         const CvMat* _missing_mask, CvRTParams params )
  {
      clear();
  
      CvDTreeParams tree_params( params.max_depth, params.min_sample_count,
          params.regression_accuracy, params.use_surrogates, params.max_categories,
--- 260,305 ----
  bool CvRTrees::train( const CvMat* _train_data, int _tflag,
                          const CvMat* _responses, const CvMat* _var_idx,
                          const CvMat* _sample_idx, const CvMat* _var_type,
!                         const CvMat* _missing_mask, CvRTParams params, const int cls_count, char * priorsStr)
  {
      clear();
+     //scPA  Set the priors to priorsStr or by default to [1,1, ...]. They will be later scaled. 
+     float *pseudoPriors = new float[cls_count];
+     for (int i=0; i<cls_count; i++)
+          pseudoPriors[i] = 1.0;
+     if (priorsStr != NULL)
+     {
+         string str(priorsStr);
+         if (str.length() >= 5) // minimum would be something like: [1 1] since we will have to be at least 2 values for the class
+         {
+             if (str[0]=='[' and str[str.length()-1] == ']')
+             {
+                 str = str.substr(1,str.length()-2);
+                 string buf; // Have a buffer string
+                 stringstream ss(str); // Insert the string into a stream
+ 
+                 vector<string> tokens; // Create vector to hold our words
+ 
+                 while (ss >> buf)
+                      tokens.push_back(buf);
+                 if (tokens.size() == cls_count)
+                     for (int i = 0;i<tokens.size();i++)
+                         pseudoPriors[i] = atof(tokens[i].c_str());
+                 else
+                     printf("The number of priors specified are different from the cls_count. Default priors will be used.\n");
+ 
+             }
+             else
+                 printf("The priors passed are not in a list form. Default priors will be used.\n");
+         }
+         else
+             printf("The priors passed are not in the correct format. Default priors will be used.\n");
+     }
+     //Assign the priors to the params
+     if (cls_count > 0)
+          params.priors = pseudoPriors;
+ 
+     //ecPA
  
      CvDTreeParams tree_params( params.max_depth, params.min_sample_count,
          params.regression_accuracy, params.use_surrogates, params.max_categories,
***************
*** 821,837 ****
  }
  
  using namespace cv;
! 
  bool CvRTrees::train( const Mat& _train_data, int _tflag,
                       const Mat& _responses, const Mat& _var_idx,
                       const Mat& _sample_idx, const Mat& _var_type,
!                      const Mat& _missing_mask, CvRTParams _params )
  {
      CvMat tdata = _train_data, responses = _responses, vidx = _var_idx,
      sidx = _sample_idx, vtype = _var_type, mmask = _missing_mask;
      return train(&tdata, _tflag, &responses, vidx.data.ptr ? &vidx : 0,
                   sidx.data.ptr ? &sidx : 0, vtype.data.ptr ? &vtype : 0,
!                  mmask.data.ptr ? &mmask : 0, _params);
  }
  
  
--- 863,879 ----
  }
  
  using namespace cv;
! //scPA     Added 2 parameters //ecPA
  bool CvRTrees::train( const Mat& _train_data, int _tflag,
                       const Mat& _responses, const Mat& _var_idx,
                       const Mat& _sample_idx, const Mat& _var_type,
!                      const Mat& _missing_mask, CvRTParams _params, const int cls_count, char* priorsStr)
  {
      CvMat tdata = _train_data, responses = _responses, vidx = _var_idx,
      sidx = _sample_idx, vtype = _var_type, mmask = _missing_mask;
      return train(&tdata, _tflag, &responses, vidx.data.ptr ? &vidx : 0,
                   sidx.data.ptr ? &sidx : 0, vtype.data.ptr ? &vtype : 0,
!                  mmask.data.ptr ? &mmask : 0, _params, cls_count, priorsStr);
  }
  
  
diff -crBN AZOrange/orangeDependencies/src/opencv-2.0.0/src/ml/mlann_mlp.cpp AZOrangeExported/orangeDependencies/src/opencv-2.0.0/src/ml/mlann_mlp.cpp
*** AZOrange/orangeDependencies/src/opencv-2.0.0/src/ml/mlann_mlp.cpp   2009-10-01 01:20:59.000000000 +0100
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/src/ml/mlann_mlp.cpp   2011-02-02 10:29:12.261770061 +0000
***************
*** 173,181 ****
  }
  
  
! void CvANN_MLP::init_weights()
  {
      int i, j, k;
  
      for( i = 1; i < layer_sizes->cols; i++ )
      {
--- 173,185 ----
  }
  
  
! void CvANN_MLP::init_weights(int seed)
  {
      int i, j, k;
+     //scPA  force to use a specific seed
+     if (seed !=0)
+         rng = cvRNG(seed);
+     //ecPA
  
      for( i = 1; i < layer_sizes->cols; i++ )
      {
***************
*** 815,823 ****
  
  int CvANN_MLP::train( const CvMat* _inputs, const CvMat* _outputs,
                        const CvMat* _sample_weights, const CvMat* _sample_idx,
!                       CvANN_MLP_TrainParams _params, int flags )
  {
!     const int MAX_ITER = 1000;
      const double DEFAULT_EPSILON = FLT_EPSILON;
  
      double* sw = 0;
--- 819,829 ----
  
  int CvANN_MLP::train( const CvMat* _inputs, const CvMat* _outputs,
                        const CvMat* _sample_weights, const CvMat* _sample_idx,
!                       CvANN_MLP_TrainParams _params, int flags, int seed, int nIterStep, const CvMat* _inputs_val, const CvMat* _outputs_val )
  {
!     //scPA Changed MAX_ITER from 1000 to 20000
!     const int MAX_ITER = 20000;
!     //ecPA
      const double DEFAULT_EPSILON = FLT_EPSILON;
  
      double* sw = 0;
***************
*** 841,847 ****
  
      // ... and link weights
      if( !(flags & UPDATE_WEIGHTS) )
!         init_weights();
  
      max_iter = params.term_crit.type & CV_TERMCRIT_ITER ? params.term_crit.max_iter : MAX_ITER;
      max_iter = MIN( max_iter, MAX_ITER );
--- 847,853 ----
  
      // ... and link weights
      if( !(flags & UPDATE_WEIGHTS) )
!         init_weights(seed);
  
      max_iter = params.term_crit.type & CV_TERMCRIT_ITER ? params.term_crit.max_iter : MAX_ITER;
      max_iter = MIN( max_iter, MAX_ITER );
***************
*** 860,866 ****
      }
      else
      {
!         CV_CALL( iter = train_rprop( x0, u, sw ));
      }
  
      __END__;
--- 866,872 ----
      }
      else
      {
!         CV_CALL( iter = train_rprop( x0, u, sw, nIterStep, _inputs_val, _outputs_val));
      }
  
      __END__;
***************
*** 1046,1052 ****
  }
  
  
! int CvANN_MLP::train_rprop( CvVectors x0, CvVectors u, const double* sw )
  {
      const int max_buf_sz = 1 << 16;
      CvMat* dw = 0;
--- 1052,1058 ----
  }
  
  
! int CvANN_MLP::train_rprop( CvVectors x0, CvVectors u, const double* sw, int nIterStep, const CvMat* _inputs_val, const CvMat* _outputs_val)
  {
      const int max_buf_sz = 1 << 16;
      CvMat* dw = 0;
***************
*** 1055,1066 ****
      CvMat* buf = 0;
      double **x = 0, **df = 0;
      int iter = -1, count = x0.count;
  
      CV_FUNCNAME( "CvANN_MLP::train" );
  
      __BEGIN__;
  
!     int i, ivcount, ovcount, l_count, total = 0, max_iter, buf_sz, dcount0, dcount=0;
      double *buf_ptr;
      double prev_E = DBL_MAX*0.5, epsilon;
      double dw_plus, dw_minus, dw_min, dw_max;
--- 1061,1082 ----
      CvMat* buf = 0;
      double **x = 0, **df = 0;
      int iter = -1, count = x0.count;
+     int UPstrips = 0;   // Number of sucessive increasinf Strips
+     int maxCorrect = 0;  //Number of Maximum correct classes over all iterations when predicting on validationData (Classification)
+     int lastCorrectClasses=0;
+     double lastRMSE = DBL_MAX;
+     double minRMSE = DBL_MAX;  //min RMES over all iterations when predicting on validationData (Regression)
+     int bestIter = 0;
+     bool optimizing = false;
+     CvMat* BestWeights = 0; 
+     BestWeights = cvCreateMat( wbuf->rows, wbuf->cols, wbuf->type );
+     cvZero( BestWeights );
  
      CV_FUNCNAME( "CvANN_MLP::train" );
  
      __BEGIN__;
  
!     int i,j, ivcount, ovcount, l_count, total = 0, max_iter, buf_sz, dcount0, dcount=0;
      double *buf_ptr;
      double prev_E = DBL_MAX*0.5, epsilon;
      double dw_plus, dw_minus, dw_min, dw_max;
***************
*** 1178,1184 ****
  
              // calculate error
              if( u.type == CV_32F )
!                 for( i = 0; i < dcount; i++ )
                  {
                      const float* udata = u.data.fl[si+i];
                      const double* xdata = x[l_count-1] + i*ovcount;
--- 1194,1200 ----
  
              // calculate error
              if( u.type == CV_32F )
!                 for( i = 0; i < dcount; i++ )   
                  {
                      const float* udata = u.data.fl[si+i];
                      const double* xdata = x[l_count-1] + i*ovcount;
***************
*** 1279,1291 ****
                  }
              }
          }
  
!         if( fabs(prev_E - E) < epsilon )
              break;
          prev_E = E;
          E = 0;
      }
  
      __END__;
  
      cvReleaseMat( &dw );
--- 1295,1436 ----
                  }
              }
          }
+         //scPA   nIteration optimization
+         //  Early stopping - Lutz Prechelt Neural Networks 11 (1998) 761–767, PERGAMON
+         // Using Third class stopping criteria: Stop when Error on validation set increased in s sucessive strips (s = nIterStep)
+         // Error is calculated on the last ephoc of each strip
+         // nIterStep == 0  disables early stopping criteria 
+         // Each strip is hardcoded has being of lenght of 5 ephocs (iterations)
+         optimizing = (nIterStep !=0) && (_inputs_val != 0) && (_outputs_val !=0);
+         if ( optimizing && ((iter % 5) == 0))
+         {
+             //printf("   Iter %-6d ",iter); 
+             CvMat inputs = *_inputs_val, outputs;
+             double* buf;
+             buf = (double*)cvStackAlloc( (inputs.rows*ovcount)*sizeof(buf[0]) );
+             cvInitMatHeader( &outputs, inputs.rows, ovcount, CV_32FC1, buf );
+             predict(&inputs, &outputs);
+             if (ovcount > 1)  // Classification using CA
+             {
+                 int correctClasses=0;
+                 double maxOut,maxAct;
+                 int idxOut, idxAct;
+                 for (i=0;i<inputs.rows; i++)
+                 {
+                     // Find the idx for the output that has the highest value
+                     idxOut = 0;
+                     idxAct = 0;
+                     maxOut = cvGetReal2D(_outputs_val,i,idxOut) ;
+                     maxAct = cvGetReal2D(&outputs,i,idxAct) ;
+                     for( j = 1; j < ovcount; j++ )
+                         {
+                             if (cvGetReal2D(&outputs,i,j) >  cvGetReal2D(&outputs,i,idxOut))
+                                 idxOut = j;
+                                 maxOut=cvGetReal2D(&outputs,i,j);
+                             if (cvGetReal2D(_outputs_val,i,j) >  cvGetReal2D(_outputs_val,i,idxAct))
+                                 idxAct = j;
+                                 maxAct=cvGetReal2D(_outputs_val,i,j) ;
+                         }
+                     if (idxOut == idxAct)
+                         correctClasses ++;            
+                 }
+                 //printf("Acc: %5f",double(correctClasses)/double(inputs.rows));
+                 //Updating nIterStep
+                 if (correctClasses <= lastCorrectClasses)
+                     UPstrips ++;
+                 else
+                     UPstrips = 0; 
+                 //printf(" UPstrips:%5d ",UPstrips);
+                 // update n-1 strip Error
+                 lastCorrectClasses = correctClasses;
+                 // Stop criteria
+                 if ( UPstrips == nIterStep)
+                 {
+                     //printf("\nPermature stop by Acc analisys: ");
+                     //printf("Max Acc: %5f on iter n. %-5d\n",double(maxCorrect)/double(inputs.rows),bestIter);
+                     break;
+                 }
+                 // else, continue to next iterations
+                 if (correctClasses > maxCorrect)
+                 {
+                     maxCorrect = correctClasses;
+                     bestIter = iter;
+                     // Save the actual weights as the BestWeights
+                     for (i=0 ; i<wbuf->rows; i++)
+                         for(j=0; j<wbuf->cols;j++)
+                         {
+                             cvmSet(BestWeights , i,j, cvGetReal2D(wbuf,i,j) );
+                         }
+                 }
  
!                 //printf(" MaxAcc so far: %5f\n",double(maxCorrect)/double(inputs.rows));
!             }
!             else  //Regression: Using RMSE
!             {
!                 double accSum=0.0,rmse=0.0;
!                 for (i=0;i<inputs.rows; i++)
!                 {
!                     accSum += pow(cvGetReal2D(_outputs_val,i,0)-cvGetReal2D(&outputs,i,0) ,2);
!                 }
!                 rmse = sqrt(accSum/inputs.rows);
!                 //printf("RMSE: %-5f ",rmse);
! 
!                 //Updating nIterStep
!                 if (rmse > lastRMSE)
!                     UPstrips ++;
!                 else
!                     UPstrips = 0;
!                 //printf(" UPstrips:%5d ",UPstrips);
!                 // update n-1 strip error
!                 lastRMSE = rmse;
!                 // Stop criteria
!                 if ( UPstrips == nIterStep)
!                 {
!                     //printf("\nPermature stop by RMSE analisys: ");
!                     //printf("Min RMSE: %-5f on iter n. %-5d\n",minRMSE,bestIter);
!                     break;
!                 }
!                 // else, continue to next iterations
!                 if (rmse < minRMSE)
!                 {
!                     minRMSE = rmse;
!                     bestIter = iter;
!                     // Save the actual weights as the BestWeights
!                     for (i=0 ; i<wbuf->rows; i++)
!                         for(j=0; j<wbuf->cols;j++)
!                         {
!                             cvmSet(BestWeights , i,j, cvGetReal2D(wbuf,i,j) );
!                         }   
! 
! 
!                 }
!                 //printf(" min RMSE so far: %-5f\n",minRMSE);
!             }
!         }
! 
! 
!         if( (!optimizing) && (fabs(prev_E - E) < epsilon) )
!         {
!             //printf("Stoped by EPS !!\n");
              break;
+         }
          prev_E = E;
          E = 0;
      }
  
+     if (optimizing && (iter >= 5) )
+     {
+         //printf("Optimization was selected!\n");
+         // reverting to the BestWeights
+         for (i=0 ; i<wbuf->rows; i++)
+             for(j=0; j<wbuf->cols;j++)
+             {
+                 cvmSet(wbuf , i, j, cvGetReal2D(BestWeights,i,j) );
+             }
+         iter = bestIter;
+ 
+     }
+ 
      __END__;
  
      cvReleaseMat( &dw );
***************
*** 1528,1538 ****
  
  int CvANN_MLP::train( const Mat& _inputs, const Mat& _outputs,
                       const Mat& _sample_weights, const Mat& _sample_idx,
!                      CvANN_MLP_TrainParams _params, int flags )
  {
!     CvMat inputs = _inputs, outputs = _outputs, sweights = _sample_weights, sidx = _sample_idx;
      return train(&inputs, &outputs, sweights.data.ptr ? &sweights : 0,
!                  sidx.data.ptr ? &sidx : 0, _params, flags); 
  }
  
  float CvANN_MLP::predict( const Mat& _inputs, Mat& _outputs ) const
--- 1673,1683 ----
  
  int CvANN_MLP::train( const Mat& _inputs, const Mat& _outputs,
                       const Mat& _sample_weights, const Mat& _sample_idx,
!                      CvANN_MLP_TrainParams _params, int flags, int seed, int nIterStep, const Mat& _inputs_val, const Mat& _outputs_val )
  {
!     CvMat inputs = _inputs, outputs = _outputs, sweights = _sample_weights, sidx = _sample_idx, inputs_val = _inputs_val, outputs_val = _outputs_val;
      return train(&inputs, &outputs, sweights.data.ptr ? &sweights : 0,
!                  sidx.data.ptr ? &sidx : 0, _params, flags, seed, nIterStep, &inputs_val, &outputs_val); 
  }
  
  float CvANN_MLP::predict( const Mat& _inputs, Mat& _outputs ) const
diff -crBN AZOrange/orangeDependencies/src/opencv/src/ml/mlsvm.cpp AZOrangeExported/orangeDependencies/src/opencv/src/ml/mlsvm.cpp
*** AZOrange/orangeDependencies/src/opencv/src/ml/mlsvm.cpp	2009-10-01 01:20:59.000000000 +0100
--- AZOrangeExported/orangeDependencies/src/opencv/src/ml/mlsvm.cpp	2011-10-25 17:22:27.280146501 +0100
***************
*** 1563,1569 ****
      block_size = MAX( block_size, sample_count*2*(int)sizeof(double) + 1024 );
      block_size = MAX( block_size, sample_size*2 + 1024 );
  
!     CV_CALL( storage = cvCreateMemStorage(block_size));
      CV_CALL( temp_storage = cvCreateChildMemStorage(storage));
      CV_CALL( alpha = (double*)cvMemStorageAlloc(temp_storage, sample_count*sizeof(double)));
  
--- 1563,1569 ----
      block_size = MAX( block_size, sample_count*2*(int)sizeof(double) + 1024 );
      block_size = MAX( block_size, sample_size*2 + 1024 );
  
!     CV_CALL( storage = cvCreateMemStorage(block_size + sizeof(CvMemBlock) + sizeof(CvSeqBlock)));
      CV_CALL( temp_storage = cvCreateChildMemStorage(storage));
      CV_CALL( alpha = (double*)cvMemStorageAlloc(temp_storage, sample_count*sizeof(double)));
  
*** AZOrange/orangeDependencies/src/opencv-2.0.0/include/opencv/cxcore_orig.hpp	2011-12-26 12:26:15.352440192 +0000
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/include/opencv/cxcore.hpp	2011-12-26 12:27:54.260437251 +0000
***************
*** 55,60 ****
--- 55,61 ----
  #include <new>
  #include <string>
  #include <vector>
+ #include <cstddef>
  #endif // SKIP_INCLUDES
  
  namespace cv {
*** AZOrange/orangeDependencies/src/opencv-2.0.0/include/opencv/cxoperations_orig.hpp	2011-12-26 12:28:08.960436741 +0000
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/include/opencv/cxoperations.hpp	2011-12-26 12:28:44.268437778 +0000
***************
*** 45,50 ****
--- 45,51 ----
  
  #ifndef SKIP_INCLUDES
    #include <string.h>
+   #include <cstddef>
    #include <limits.h>
  #endif // SKIP_INCLUDES
  
*** AZOrange/orangeDependencies/src/opencv-2.0.0/include/opencv/cxmat_orig.hpp	2011-12-26 12:28:56.928435702 +0000
--- AZOrangeExported/orangeDependencies/src/opencv-2.0.0/include/opencv/cxmat.hpp	2011-12-26 12:29:13.360435040 +0000
***************
*** 45,50 ****
--- 45,51 ----
  
  #ifndef SKIP_INCLUDES
  #include <limits.h>
+ #include <cstddef>
  #endif // SKIP_INCLUDES
  
  #ifdef __cplusplus
